from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("extract_games_from_ogh_api").getOrCreate()
sc = spark.sparkContext

sc.install_pypi_package("requests==2.26.0")

import requests
import json
from pyspark.sql.functions import explode
from  pyspark.sql import Row
from pyspark.sql.types import StructType,StructField,StringType
import pyspark.sql.functions as F

omen_ga_master_flat_path = "s3a://hpiomen/prod/data/work/pss_analytics/prod/silver/omen_silver/omen_ga_master_flat"
omen_ga_df = spark.read.load(omen_ga_master_flat_path) 
duplicated_games_list = [Row("英雄联盟", "League of Legends"),
                    Row("穿越火线", "CrossFire"), #??
                    Row("守望先锋", "Overwatch"),
                    Row("原神", "Genshin Impact"),
                    Row("炉石传说", "Hearthstone"),
                    Row("暴雪战网", "Battle.net"), #??
                    Row("地下城与勇士", "Dungeon Fighter Online"), #??
                    Row("纸牌!", "纸牌!"), #didnt find anything
                    Row("逆战", "Assault Fire"), #??
                    Row("我的世界启动器", "Minecraft"),
                    Row("決勝時刻 現代戰爭", "Call of Duty 4: Modern Warfare"),
                    Row("魔兽世界（经典怀旧服)", "World of Warcraft"), #World of warcraft classic (considering as the same)
                    Row("星际争霸II", "StarCraft II: Wings of Liberty"), #??
                    Row("剑网3客户端", "剑网3客户端"), #didnt find anything
                    Row("フォートナイト", "Fortnite"), 
                    Row("堡垒之夜", "Fortnite"), 
                    Row("星际争霸II", "StarCraft II: Wings of Liberty"), 
                    Row("Minecraft Launcher", "Minecraft"), 
                    Row("魔兽世界", "World of Warcraft"),
                    Row("Wow", "World of Warcraft"), 
                    Row("World of Warcraft Classic", "World of Warcraft"), 
                    Row("鬼谷八荒", "Tale of Immortal"),
                    Row("使命召唤OL", "Call of Duty Online"),
]

duplicated_games_df = spark.createDataFrame(duplicated_games_list, schema=StructType([StructField("eventlabel", StringType(), True), StructField("translated_name", StringType(), True)])).withColumn("category", F.lit("Games"))

fullvisitorid_games_df = (omen_ga_df.where("eventcategory == 'MyGames' and eventaction in ('LaunchGame') and eventlabel != 'success' and eventlabel != 'failure, Error loading ; app is not installed'")
        .select("fullvisitorid", "eventlabel", "visitid", "date")
        .distinct()
        .withColumn("eventlabel", F.regexp_replace("eventlabel", "success, ", ""))
        .withColumn("eventlabel", F.regexp_replace("eventlabel", "Exception (.)* launching ", "")) #Magic expression to remove all exception related errors
        .withColumn("eventlabel", F.regexp_replace("eventlabel", " Launcher", ""))
        .join(duplicated_games_df, ["eventlabel"], "left")
        .withColumn("game_name", F.when(F.col("translated_name").isNull(), F.col("eventlabel")).otherwise(F.col("translated_name")))
        .select("fullvisitorid", "game_name", "visitid", "date")
        .distinct())

games_frequency_df = fullvisitorid_games_df.groupBy("game_name").count().orderBy(F.col("count").desc())

distinct_game_name_df = games_frequency_df.limit(12)

disinct_game_name_list = distinct_game_name_df.select("game_name").rdd.flatMap(lambda x: x).collect()
disinct_game_name_list

friendly_names = [x.replace(" ","").lower() for x in disinct_game_name_list]
friendly_names = friendly_names[:1]+friendly_names[2:]
friendly_names

from pyspark.sql.types import *
from pyspark.sql.functions import *


def flatten(df):  
   complex_fields = dict([(field.name, field.dataType)
                             for field in df.schema.fields
                             if type(field.dataType) == ArrayType or  type(field.dataType) == StructType])
   while len(complex_fields)!=0:
      col_name=list(complex_fields.keys())[0]
      print ("Processing :"+col_name+" Type : "+str(type(complex_fields[col_name])))
    
      if (type(complex_fields[col_name]) == StructType):
         expanded = [col(col_name+'.'+k).alias(col_name+'_'+k) for k in [ n.name for n in  complex_fields[col_name]]]
         df=df.select("*", *expanded).drop(col_name)
    
      elif (type(complex_fields[col_name]) == ArrayType):    
         df=df.withColumn(col_name,explode_outer(col_name))
          
      complex_fields = dict([(field.name, field.dataType)
                             for field in df.schema.fields
                             if type(field.dataType) == ArrayType or  type(field.dataType) == StructType])
   return df


env_url = "https://staging.hpgamestream.com"
url = env_url +"/api/applist/games"
game_token = "ImrCwpODcEOIvicnJT39BQ=="
headers = { 'Authorization': game_token , 'Version':'2','Content-Type':'application/json' }

body = '['
for i in range(len(friendly_names)):
    if i != len(friendly_names)-1:
        body += '{"id": "123","friendlyName": "'+friendly_names[i]+'","appType": "game"},'
    else:
        body += '{"id": "123","friendlyName": "'+friendly_names[i]+'","appType": "game"}'

body += ']'
print((body))

response = requests.post(url, headers=headers, data=json.dumps(json.loads(body)))
games_json = json.loads(response.text)
response.text

df = sc.parallelize(games_json["games"]).map(lambda x: json.dumps(x))
df = spark.read.json(df)

df.select("friendlyname").distinct().show()

selected_game_df = flatten(df)
selected_game_df = selected_game_df.select("friendlyname","apptype","executable","artworkid","metadataid","blacklisted").distinct()

selected_game_df.createOrReplaceTempView("games")

distinct_metadataId_df = spark.sql("select distinct(metadataId) from games")

distinct_metadataId = distinct_metadataId_df.select("metadataId").rdd.flatMap(lambda x: x).collect()

distinct_metadataId
distinct_metadataId = str(distinct_metadataId).replace("'","\"")
distinct_metadataId

metadata_env_url = "https://staging-apigateway.hpgamestream.com"
metadata_url = metadata_env_url + "/myGamesMetadataDistribution"
metadata_headers = {"x-api-key":"1qPFd6Na6V3UbXIdrmYPt17Oc0bEnv8S5yPaxJDM","language":"us-en","country":"us","Cache-Control":"max-age=0"}

response = requests.post(metadata_url, headers = metadata_headers, data=str(distinct_metadataId))
response.text

metadata_json = json.loads(response.text)

len(metadata_json)

metadata = sc.parallelize(metadata_json).map(lambda x: json.dumps(x))
metadata_df = spark.read.json(metadata)

schema = metadata_df.schema
schema

metadata_df = spark.read.json(metadata,schema=schema)
columns_list = metadata_df.columns
columns_list = [x for x in columns_list if 'screen' not in x]
columns_list
metadata_df = metadata_df.select(columns_list)
metadata_df.select("title").distinct().show()

flattend_df=flatten(metadata_df)
flattend_df.printSchema()

flattend_df.show()

flattend_df.createOrReplaceTempView("game_metadata")

%%sql

select distinct(metadataid),title from game_metadata

joined_df = spark.sql("""
select 
gm.*,
g.friendlyname,
g.apptype,
g.executable,
g.artworkid,
g.blacklisted
from 
game_metadata gm, games g 
where 
g.metadataid=gm.metadataid
""")
   

joined_df.createOrReplaceTempView("game_features")

%%sql

select distinct friendlyname from game_features

joined_df.columns

s3_path = "s3://hpiomen/prod/data/work/peripheral_recommendation/game_features/ogh_api"
joined_df.write.partitionBy('metadataId').mode("overwrite").format("csv").save(s3_path,header='true')

s3_path = "s3://hpiomen/prod/data/work/peripheral_recommendation/game_features/ogh_api"
games_df = spark.read.option("header","true").csv(s3_path)
games_df.show(10)


